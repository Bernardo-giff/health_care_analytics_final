---
title: "Health care analytics individual assignment"
subtitle: "The importance of early life dietary education and habits in long term BMI"
output: html_document
date: "2024-06-16"
---

# Introduction

In this file, we will focus on the code and statistical methods to produce the anaysis. This is also available in the remote repo:

[git repo here](https://github.com/Bernardo-giff/health_care_analytics_final)

```{r, message=FALSE, warning=FALSE}
# Set the working dir
setwd('/Users/bernardocarvalho/Library/CloudStorage/OneDrive-ImperialCollegeLondon/2024/Health care analytics')

# Get necessary libraries
library(dplyr)
library(stargazer)
library(stringr)
library(ggplot2)
library(UpSetR)
library(naniar)
library(tidyr)

```

# Importing data

In the table below we can see the the Diagram of the study's structure. We will use data from wave 1 (main survey and contextual data) and wave 5

![](./images/study_diagram.png)

The dataset has been loaded on the local machine. You can download it [from this link](https://www.icpsr.umich.edu/web/DSDR/studies/21600/versions/V25/download/rdata?path=/pcms/studies/0/2/1/6/21600/V25). After extracting the dataset, we merge the three files into one by the AID key.

```{r}
# Set dir for the files
path = "ICPSR_21600/"

# Loading the dataset (in-home) for wave 1
load(paste0(path, "DS0001/21600-0001-Data.rda"))

# Loading context data for wave 1
load(paste0(path, "DS0002/21600-0002-Data.rda"))

# Loading the dataset (multi-modal) for wave 5
load(paste0(path, "DS0032/21600-0032-Data.rda"))

# Renaming the datasets
w1_data = da21600.0001
w1_contextual = da21600.0002
w5_data = da21600.0032

# Removing the original uploads
rm(da21600.0001)
rm(da21600.0002)
rm(da21600.0032)

# Finally, we create a dataset composed of the merging of wave data 1 and 5
data = merge(w1_data, w1_contextual, by = "AID")
data = merge(data, w5_data, by = "AID")
```

# Data cleaning and EDA

Our main goal is to establish a relationship between early exposure to dietary knowledge and good habits and the BMI metric at a later stage in life. Therefore, we select only the relevant data points to that goal.

```{r}
# Selecting only the canidate variables
data <- data %>%
  select(   
    H5ID3                # Weight in pounds (wave 5)
    , H5ID2F             # Height in feet (wave 5)
    , H5ID2I             # Height in inches (wave 5)
    , AID                # Respondent Identifier
    , BIO_SEX            # Biological Sex - Wave I
    , H1GH59A            # Height in feet - Wave I
    , H1GH59B            # Height in inches - Wave I 
    , H1GH60             # Weight in pounds - Wave I
    , S63                # Exercise - Wave I
    , H1WP8              # Dinner with Parents - Wave I
    , H1GH34             # Ate Vegetables Yesterday - Wave I
    , H1WP7              # Make Own Decisions About Diet - Wave I
    # Start of "What do you usually have for breakfast on a weekday morning?" block
    , H1GH23A            # Milk
    , H1GH23B            # coffee or tea
    , H1GH23C            # cereal
    , H1GH23D            # fruit, juice
    , H1GH23E            # eggs
    , H1GH23F            # meat
    , H1GH23G            # snack food
    , H1GH23H            # bread toast or rolls
    , H1GH23I            # other items
    , H1GH23J            # Nothing
    # End of "What do you usually have for breakfast on a weekday morning?" block
    , H1GH1              # General Health - Wave I
    , H1GH51             # Sleep - Wave I
    , H1TS4              # Learned Problems of Obesity - Wave I
    , H1TS1              # Learned Proper Diet - Wave I
    , H1TS2              # Learned about the importance of exercise - Wave I
    , PA55               # Total Household Income 1994
    , BST90P02           # Modal Race (Wave 1 context)
    , BST90P01           # Urbanicity Code (Wave 1 context)
  )
```

We quickly glance at the profile of missing data for this sample. We see that aside from income (in wave 1) and exercise information (in wave 5), we do not have a significant issue with missing data. We will tackle that later on.

```{r}
# Plotting missing data density
vis_miss(data)

```

The following plot shows the size of the intersection of missing data between variables. We also don't observe very significant patterns of joint occurrence.

```{r}
# Plotting the intersection between missing values
gg_miss_upset(data)
```

Next we need to transform the height and weight variables to the metric system. Both our independent and dependent variables rely on it (BMI).

```{r}

# Convert weight and height measures to the metric system
data <- data %>%
  mutate(
    # Extract values from Wave 1
    w1_height_feet = as.numeric(sub(".*\\) (\\d+).*", "\\1", as.character(H1GH59A))),
    w1_height_inches = as.numeric(sub(".*\\) (\\d+).*", "\\1", as.character(H1GH59B))),
    
    # Combine height data from feet and inches to total inches
    w1_total_inches = (w1_height_feet * 12) + w1_height_inches,
    
    # Convert height from inches to meters
    w1_height_cm = w1_total_inches * 0.0254,
    
    # Convert weight from pounds to kilograms
    w1_weight_kg = H1GH60 * 0.453592,
    
    # Calculate bmi in weight 1
    w1_bmi = w1_weight_kg / (w1_height_cm ^ 2),
    
    # Extract values from Wave 5
    w5_height_feet = as.numeric(sub(".*\\) (\\d+).*", "\\1", as.character(H5ID2F))),
    w5_height_inches = as.numeric(sub(".*\\) (\\d+).*", "\\1", as.character(H5ID2I))),
    
    # Combine height data from feet and inches to total inches
    w5_total_inches = (w5_height_feet * 12) + w5_height_inches,
    
    # Convert height from inches to meters
    w5_height_cm = w5_total_inches * 0.0254,
    
    # Convert weight from pounds to kilograms
    w5_weight_kg = H5ID3 * 0.453592,
    
    # Calculate bmi in weight 5
    w5_bmi = w5_weight_kg / (w5_height_cm ^ 2)
    
  )  %>%
  # Drop auxiliary columns created and old columns
  select(
    -w1_height_feet
    , -w1_height_inches
    , -w1_total_inches
    , -w1_height_cm
    , -w1_weight_kg
    , -w5_height_feet
    , -w5_height_inches
    , -w5_total_inches
    , -w5_height_cm
    , -w5_weight_kg
    , -H1GH59A
    , -H1GH59B
    , -H5ID2F
    , -H5ID2I
    , -H1GH60
    , -H5ID3
    )
```

We quickly inspect the amount of missing data in these variables

```{r}
vis_miss(data %>% select(w5_bmi, w1_bmi))

```

Since the total amount of missing variables is only 3% for the first wave, we should drop them, since the hypothesis we are testing relies on this information and the proportion is small. We will deal with the NAs after all of the relevant data transformations have been made.

Next, we start recasting the columns data to factors, cleaning up some of the options and casting the responses that we can't do anything with as NAs

```{r, warning=FALSE}

data <- data %>%
  mutate(
    # Convert Sex to factors, handle missing values
    BIO_SEX = factor(BIO_SEX, 
                     levels = 
                       c("(1) (1) Male"
                         , "(2) (2) Female"
                         , "(6) (6) Refused"), 
                     labels = 
                       c("Male"
                         , "Female"
                         , "Refused"))
    # Convert refused to NA
    , BIO_SEX = replace(BIO_SEX, BIO_SEX == "Refused", NA)
    
    # Convert Exercise to factors, handle missing values
    , w5_exercise = factor(S63, 
                         levels = 
                           c("(0) (0) Never"
                             , "(1) (1) 1 or 2 times"
                             , "(2) (2) 3 to 5 times"
                             , "(3) (3) 6 or 7 times"
                             , "(4) (4) More than 7 times"
                             , "(9) (9) Multiple response"), 
                         labels = 
                           c("Never"
                             , "1 or 2 times"
                             , "3 to 5 times"
                             , "6 or 7 times"
                             , "More than 7 times"
                             , "Multiple response")),
    
    # Coalesce NAs
    , w5_exercise = replace(w5_exercise, w5_exercise == "Multiple response", NA)
    
    # Extract dinner with parents frequency
    , w1_dinner_with_parents = as.numeric(sub(".*\\) (\\d+).*", "\\1", 
                               as.character(H1WP8)))
    
    # Coalesce NAs
    , w1_dinner_with_parents = replace(w1_dinner_with_parents, 
                                       w1_dinner_with_parents %in% c(96, 97, 98), NA)
    
    # Convert general health (wave 1) to factors, handle missing values
    , w1_general_health = factor(H1GH1, 
                                 levels = 
                                   c("(1) (1) Excellent"
                                     , "(2) (2) Very good"
                                     , "(3) (3) Good"
                                     , "(4) (4) Fair"
                                     , "(5) (5) Poor"
                                     , "(6) (6) Refused"
                                     , "(8) (8) Don't know"),
                                  labels = 
                                    c("Excellent"
                                      , "Very good"
                                      , "Good"
                                      , "Fair"
                                      , "Poor"
                                      , "Refused"
                                      , "Don't know"))
    
    # Coalesce NAs
    , w1_general_health = replace(w1_general_health
                                , w1_general_health %in% c("Refused", "Don't know"), NA)
    
    # Convert learning problems of obesity to factors, handle missing values
    , w1_learned_problems_obesity = factor(H1TS4, 
                                         levels = 
                                           c("(0) (0) No"
                                             , "(1) (1) Yes"
                                             , "(6) (6) Refused"
                                             , "(8) (8) Don't know"),
                                         labels = 
                                           c("No"
                                             , "Yes"
                                             , "Refused"
                                             , "Don't know"))
    # Coalesce NAs
    , w1_learned_problems_obesity = replace(w1_learned_problems_obesity, 
                                          w1_learned_problems_obesity %in% 
                                            c("Refused", "Don't know"), NA)
    
    # Convert learning the importance of exercise to factors, handle missing values
    , w1_learned_importance_exercise = factor(H1TS2, 
                                         levels = 
                                           c("(0) (0) No"
                                             , "(1) (1) Yes"
                                             , "(6) (6) Refused"
                                             , "(8) (8) Don't know"),
                                         labels = 
                                           c("No"
                                             , "Yes"
                                             , "Refused"
                                             , "Don't know"))
    # Coalesce NAs
    , w1_learned_importance_exercise = replace(w1_learned_importance_exercise, 
                                          w1_learned_importance_exercise %in% 
                                            c("Refused", "Don't know"), NA),
    
    # Convert learning proper diet to factors, handle missing values
    , w1_learned_diet = factor(H1TS1, 
                             levels = 
                               c("(0) (0) No"
                                 , "(1) (1) Yes"
                                 , "(6) (6) Refused"
                                 , "(8) (8) Don't know"),
                              labels = 
                               c("No"
                                 , "Yes"
                                 , "Refused"
                                 , "Don't know"))
    # Coalesce NAs
    , w1_learned_diet = replace(w1_learned_diet, 
                              w1_learned_diet %in% c("Refused", "Don't know"), NA)
    
    # Convert usual breakfast data -> Milk
    , w1_usual_breakfast_milk = factor(H1GH23A, 
                             levels = 
                               c("(0) (0) Not marked"
                                 , "(1) (1) Marked"
                                 , "(6) (6) Refused"
                                 , "(8) (8) Don't know"),
                              labels = 
                               c("No"
                                 , "Yes"
                                 , "Refused"
                                 , "Don't know"))
    # Coalesce NAs
    , w1_usual_breakfast_milk = replace(w1_usual_breakfast_milk, 
                              w1_usual_breakfast_milk %in% c("Refused", "Don't know"), NA)
    
    # Convert usual breakfast data -> Cereal
    , w1_usual_breakfast_cereal = factor(H1GH23C, 
                             levels = 
                               c("(0) (0) Not marked"
                                 , "(1) (1) Marked"
                                 , "(6) (6) Refused"
                                 , "(8) (8) Don't know"),
                              labels = 
                               c("No"
                                 , "Yes"
                                 , "Refused"
                                 , "Don't know"))
    # Coalesce NAs
    , w1_usual_breakfast_cereal = replace(w1_usual_breakfast_cereal, 
                              w1_usual_breakfast_cereal %in% c("Refused", "Don't know"), NA)
    
    # Convert usual breakfast data -> Fruit
    , w1_usual_breakfast_fruit = factor(H1GH23D, 
                             levels = 
                               c("(0) (0) Not marked"
                                 , "(1) (1) Marked"
                                 , "(6) (6) Refused"
                                 , "(8) (8) Don't know"),
                              labels = 
                               c("No"
                                 , "Yes"
                                 , "Refused"
                                 , "Don't know"))
    # Coalesce NAs
    , w1_usual_breakfast_fruit = replace(w1_usual_breakfast_fruit, 
                              w1_usual_breakfast_fruit %in% c("Refused", "Don't know"), NA)
    
    # Convert usual breakfast data -> Eggs
    , w1_usual_breakfast_eggs = factor(H1GH23E, 
                             levels = 
                               c("(0) (0) Not marked"
                                 , "(1) (1) Marked"
                                 , "(6) (6) Refused"
                                 , "(8) (8) Don't know"),
                              labels = 
                               c("No"
                                 , "Yes"
                                 , "Refused"
                                 , "Don't know"))
    # Coalesce NAs
    , w1_usual_breakfast_eggs = replace(w1_usual_breakfast_eggs, 
                              w1_usual_breakfast_eggs %in% c("Refused", "Don't know"), NA)
    
    # Convert usual breakfast data -> Meat
    , w1_usual_breakfast_meat = factor(H1GH23F, 
                             levels = 
                               c("(0) (0) Not marked"
                                 , "(1) (1) Marked"
                                 , "(6) (6) Refused"
                                 , "(8) (8) Don't know"),
                              labels = 
                               c("No"
                                 , "Yes"
                                 , "Refused"
                                 , "Don't know"))
    # Coalesce NAs
    , w1_usual_breakfast_meat = replace(w1_usual_breakfast_meat, 
                              w1_usual_breakfast_meat %in% c("Refused", "Don't know"), NA)
    
    # Convert usual breakfast data -> Snack
    , w1_usual_breakfast_snack = factor(H1GH23G, 
                             levels = 
                               c("(0) (0) Not marked"
                                 , "(1) (1) Marked"
                                 , "(6) (6) Refused"
                                 , "(8) (8) Don't know"),
                              labels = 
                               c("No"
                                 , "Yes"
                                 , "Refused"
                                 , "Don't know"))
    # Coalesce NAs
    , w1_usual_breakfast_snack = replace(w1_usual_breakfast_snack, 
                              w1_usual_breakfast_snack %in% c("Refused", "Don't know"), NA)
    
    # Convert usual breakfast data -> Bread
    , w1_usual_breakfast_bread = factor(H1GH23H, 
                             levels = 
                               c("(0) (0) Not marked"
                                 , "(1) (1) Marked"
                                 , "(6) (6) Refused"
                                 , "(8) (8) Don't know"),
                              labels = 
                               c("No"
                                 , "Yes"
                                 , "Refused"
                                 , "Don't know"))
    # Coalesce NAs
    , w1_usual_breakfast_bread = replace(w1_usual_breakfast_bread, 
                              w1_usual_breakfast_bread %in% c("Refused", "Don't know"), NA)
    
    
    # Convert Ethnicity to factors, handle missing values
    , w1_ethnicity = factor(BST90P02, 
                            levels = 
                              c("(1) (1) White"
                                , "(2) (2) Black"
                                , "(3) (3) Other"
                                , "(8) (8) Unstable estimates"
                                , "(9) (9) Geocode missing"),
                            labels = 
                              c("White"
                                , "Black"
                                , "Other"
                                , "Unstable estimates"
                                , "Geocode missing"))
    
    # Coalesce NAs
    , w1_ethnicity = replace(w1_ethnicity, w1_ethnicity %in% 
                               c("Unstable estimates", "Geocode missing"), NA),
    
    # Convert Urbanity to factors, handle missing values
    , w1_urbanity = factor(BST90P01, 
                           levels = c("(1) (1) Completely urban"
                                      , "(2) (2) Not completely urban"
                                      , "(8) (8) Unstable estimates"
                                      , "(9) (9) Geocode missing"),
                           labels = c("Completely urban"
                                      , "Not completely urban"
                                      , "Unstable estimates"
                                      , "Geocode missing")),
    , w1_urbanity = replace(w1_urbanity, w1_urbanity %in% c("Unstable estimates", "Geocode missing"), NA),
    
    # Multiply income by 1000 to get value in USD
    , w1_income_1994 = PA55 * 1000
    ) %>%
    # Remove unnecessary columns columns
    select(
        -AID                # Respondent Identifier
        , -S63                # Exercise - Wave I
        , -H1WP8              # Dinner with Parents - Wave I
        , -H1GH34             # Ate Vegetables Yesterday - Wave I
        , -H1WP7              # Make Own Decisions About Diet - Wave I
        # What do you usually have for breakfast on a weekday morning?
        , -H1GH23A            # Milk
        , -H1GH23B            # coffee or tea
        , -H1GH23C            # cereal
        , -H1GH23D            # fruit, juice
        , -H1GH23E            # eggs
        , -H1GH23F            # meat
        , -H1GH23G            # snack food
        , -H1GH23H            # bread toast or rolls
        , -H1GH23I            # other items
        , -H1GH23J            # Nothing
        # End of "What do you usually have for breakfast on a weekday morning?" blcok
        , -H1GH1              # General Health - Wave I
        , -H1GH51             # Sleep - Wave I
        , -H1TS4              # Learned Problems of Obesity - Wave I
        , -H1TS1              # Learned Proper Diet - Wave I
        , -H1TS2              # Learned importance of exercise - Wave I
        , -PA55               # Total Household Income 1994
        , -BST90P02           # Modal Race (Wave 1 context)
        , -BST90P01           # Urbanicity Code (Wave 1 context)
    )
```

After these transformations, we analyse again the profile of missing data of our study.

```{r}
vis_miss(data)
```

We proceed by investigating the distributions of the variables chosen for analyses to lay out our hypotheses. In this step we will also decide what to do with the varibles that present a high missing rate:

1.  Exercise
2.  Income
3.  Dinner with Parents

## Gender

Firstly, we look at gender. We see that that are more women in the sample than men.

```{r}

# Plot bar plot for 'Sex' variable
# Calculate proportions
data_prop <- data %>%
  group_by(BIO_SEX) %>%
  summarise(count = n()) %>%
  mutate(proportion = count / sum(count))

# Plot bar plot for 'Sex' variable showing proportions
ggplot(data_prop, aes(x = BIO_SEX, y = proportion, fill = BIO_SEX)) +
  geom_bar(stat = "identity") +
  labs(title = "Proportion of Biological Sex", x = "Bio sex", y = "Proportion") +
  scale_y_continuous(labels = scales::percent_format()) +
  theme_minimal()

```

We will not reweigh these variables, and simply discuss this in the limitations of this study.

## Exercise (wave 5)

```{r}
# Check for NAs in the 'Exercise' variable
num_na_exercise <- sum(is.na(data$w5_exercise))

# Plot bar plot for 'Exercise' variable
ggplot(data, aes(x = w5_exercise)) +
  geom_bar() +
  labs(title = "Distribution of Exercise", x = "Exercise Frequency", y = "Count") +
  theme_minimal()

```

In the case of exercise, we see that we have a lot of missing variables. There are several approaches we could take here. We cannot really drop these observations as they are a large proportion of the entire dataset. We will instead imput the mode.

```{r}
# Find the mode for Exercise
mode_exercise <- names(sort(table(data$w5_exercise), decreasing = TRUE))[1]

# Impute missing values in Exercise with the mode
data$w5_exercise[is.na(data$w5_exercise)] <- mode_exercise

# Convert Exercise back to factor to maintain the original categories
data$w5_exercise <- factor(data$w5_exercise, 
                           levels = 
                             c("Never"
                               , "1 or 2 times"
                               , "3 to 5 times"
                               , "6 or 7 times"
                               , "More than 7 times"))

# Plot the distribution of Exercise after imputing NAs
ggplot(data, aes(x = w5_exercise)) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Distribution of Exercise (After Imputing NAs)", x = "Exercise Frequency", y = "Count") +
  theme_minimal()

```

## Dinner with parents (wave 1)

```{r}
# Plot distribution for Days_Having_Dinner_with_Parents
ggplot(data, aes(x = w1_dinner_with_parents)) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Distribution of Days Having Dinner with Parents", x = "Days Having Dinner with Parents", y = "Count")

# Check the number of NAs in Days_Having_Dinner_with_Parents
table(is.na(data$w1_dinner_with_parents))
```

We see that most children of the study have dinner with their parents every day. However, we still have some 400 samples missing this information. Our first instinct is to imput with the mean. However, the mean might not be a good representation for this distribution. In the lack of a better approach we proceed with the mean but this is a clear limitation.

```{r}
# Calculate the mean for Days_Having_Dinner_with_Parents and round it to the nearest whole number
mean_dinner <- round(mean(data$w1_dinner_with_parents, na.rm = TRUE))

# Impute missing values with the rounded mean
data <- data %>%
  mutate(w1_dinner_with_parents = ifelse(is.na(w1_dinner_with_parents), 
                                         mean_dinner, 
                                         w1_dinner_with_parents))

# Plot the distribution after imputation
ggplot(data, aes(x = w1_dinner_with_parents)) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Distribution of Days Having Dinner with Parents (After Imputing NAs)", x = "Days Having Dinner with Parents", y = "Count") +
  theme_minimal()
```

## Education questions

```{r}
data_long <- data %>%
  pivot_longer(cols = c(w1_learned_diet, 
                        w1_learned_problems_obesity, 
                        w1_learned_importance_exercise), 
               names_to = "Question", 
               values_to = "Response") %>%
  drop_na(Response)

data_long <- data_long %>%
  mutate(Question = recode(Question,
                           w1_learned_diet = "Learned About Diet",
                           w1_learned_problems_obesity = "Learned About Problems of Obesity",
                           w1_learned_importance_exercise = "Learned About Importance of Exercise"))

# Calculate the proportion of each response within each question
data_long_proportion <- data_long %>%
  group_by(Question, Response) %>%
  summarize(Count = n()) %>%
  mutate(Proportion = Count / sum(Count))

# Plot the data
ggplot(data_long_proportion, aes(x = Response, y = Proportion, fill = Question)) +
  geom_bar(stat = "identity", position = "dodge", color = "black") +
  labs(title = "Distribution of Responses for Each Question",
       x = "Response",
       y = "Proportion") +
  theme_minimal() +
  scale_fill_brewer(palette = "Pastel1")
```

## Household income

```{r}
# Summary statistics for Total_Household_Income_1994
summary(data$w1_income_1994)

# Check for missing values
sum(is.na(data$w1_income_1994))

# Histogram for Total_Household_Income_1994
ggplot(data, aes(x = w1_income_1994)) +
  geom_histogram(binwidth = 5000, fill = "skyblue", color = "black") +
  labs(title = "Distribution of Total Household Income (1994)", x = "Total Household Income (in dollars)", y = "Count") +
  theme_minimal()

# Boxplot for Total_Household_Income_1994
ggplot(data, aes(x = w1_income_1994)) +
  geom_boxplot(fill = "skyblue", color = "black") +
  labs(title = "Boxplot of Total Household Income (1994)", x = "Total Household Income (in dollars)") +
  theme_minimal()
```

Imputing NAs with the mean and looking at log of total income and examine the distribution.

```{r}
# Get mean value of income
mean_income <- mean(data$w1_income_1994, na.rm = TRUE)

# Imput missing values with the mean
data <- data %>%
  mutate(w1_income_1994 = ifelse(is.na(w1_income_1994), mean_income, w1_income_1994))

# Get the log of household from the new imputed income
data <- data %>%
  mutate(w1_income_1994_log = log10(w1_income_1994))

# Plot the distribution of the log-transformed income
ggplot(data, aes(x = w1_income_1994_log)) +
  geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black") +
  labs(title = "Distribution of Log-Transformed Total Household Income (1994)", x = "Log10(Total Household Income 1994)", y = "Count") +
  theme_minimal()

# Summary statistics for the log-transformed Total_Household_Income_1994
summary(data$w1_income_1994_log)
# Boxplot for the log-transformed Total Household Income (1994)
ggplot(data, aes(y = w1_income_1994_log)) +
  geom_boxplot(fill = "skyblue", color = "black") +
  labs(title = "Boxplot of Log-Transformed Total Household Income (1994)", y = "Log10(Total Household Income 1994)") +
  theme_minimal()
```

Lastly, we handle the outliers of the income variable

```{r}
# Winsorizing function
winsorize <- function(x, lower_quantile = 0.01, upper_quantile = 0.99) {
  lower_bound <- quantile(x, lower_quantile, na.rm = TRUE)
  upper_bound <- quantile(x, upper_quantile, na.rm = TRUE)
  x[x < lower_bound] <- lower_bound
  x[x > upper_bound] <- upper_bound
  return(x)
}

# Apply Winsorizing to the log-transformed total household income
data <- data %>%
  mutate(w1_income_1994_log_win = winsorize(w1_income_1994_log))

# Plot the distribution of the winsorized log-transformed total household income
ggplot(data, aes(x = w1_income_1994_log_win)) +
  geom_histogram(binwidth = 0.1, fill = "skyblue", color = "black") +
  labs(title = "Distribution of Winsorized Log-Transformed Total Household Income (1994)", x = "Winsorized Log10(Total Household Income 1994)", y = "Count") +
  theme_minimal()

# Boxplot for the winsorized log-transformed total household income
ggplot(data, aes(y = w1_income_1994_log_win)) +
  geom_boxplot(fill = "skyblue", color = "black") +
  labs(title = "Boxplot of Winsorized Log-Transformed Total Household Income (1994)", y = "Winsorized Log10(Total Household Income 1994)") +
  theme_minimal()

# Summary statistics for the winsorized log-transformed total household income
summary(data$w1_income_1994_log_win)
```

After cleaning up the income, dinner with parents and exercise data, we see that we have only a few rows with missing data. Therefore, we drop all remaining NAs to carry on with the analysis.

```{r}
vis_miss(data)
```

```{r}
# Remove all missing data rows
data <- data[complete.cases(data), ]

# Visualize results
vis_miss(data)
```

We carry on the analysis of distributions without any NA

## Ethnicity

Next, we analyse the proportions of ethnicity in our dataset. The results are shown below:

```{r}
# Calculate counts and proportions
race_counts <- data %>%
  count(w1_ethnicity) %>%
  mutate(proportion = n / sum(n))

# Plot the distribution of Race with proportions
ggplot(race_counts, aes(x = w1_ethnicity, y = n)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  geom_text(aes(label = scales::percent(proportion)), vjust = -0.5) +
  labs(title = "Distribution of Race", x = "Race", y = "Count") +
  theme_minimal()

# Summary statistics for Race
summary_race <- summary(data$w1_ethnicity)
print(summary_race)
```

If we compare it with the original dataset's distribution, we see that whites become over-represented over time. However, we will not re-weight the samples.

```{r}

# Calculate counts and proportions
race_counts <- w1_contextual %>%
  count(BST90P02) %>%
  mutate(proportion = n / sum(n))

# Plot the distribution of Race with proportions
ggplot(race_counts, aes(x = BST90P02, y = n)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  geom_text(aes(label = scales::percent(proportion)), vjust = -0.5) +
  labs(title = "Distribution of Race (Original wave 1 data)", x = "Race", y = "Count") +
  theme_minimal()

# Summary statistics for Race
summary_race <- summary(data$w1_ethnicity)
print(summary_race)
```

## General health

Next, we analyse the distribution of the general health variable

```{r}
# Reorder the levels of w1_general_health
data$w1_general_health <- factor(data$w1_general_health, levels = c("Poor", "Fair", "Good", "Very good", "Excellent", NA))

# Check the distribution again
ggplot(data, aes(x = w1_general_health)) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Distribution of General Health", x = "General Health", y = "Count") +
  theme_minimal()

# Summary statistics for General_Health
summary(data$w1_general_health)
```

In order to improve the interpretation of the model, we change the health data from categorical to an integer variable that is ordinal. It is interesting that most people self-report good health.

```{r}
# Convert the factor to an integer variable
data$w1_general_health_int <- as.integer(data$w1_general_health)
```

We analyse if this profile changes for teenagers with a BMI score over 25. It doesn't

```{r}
# Filter for children over 25 BMI health reporting
data_over_25_bmi <- data %>% filter(w1_bmi > 25)

# Check the distribution again
ggplot(data_over_25_bmi, aes(x = w1_general_health)) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Distribution of General Health", x = "General Health", y = "Count") +
  theme_minimal()

# Summary statistics for General_Health
summary(data_over_25_bmi$w1_general_health)
```

```{r}
# Filter for children over 25 BMI health reporting
data_over_30_bmi <- data %>% filter(w1_bmi > 30)

# Check the distribution again
ggplot(data_over_30_bmi, aes(x = w1_general_health)) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Distribution of General Health", x = "General Health", y = "Count") +
  theme_minimal()

# Summary statistics for General_Health
summary(data_over_30_bmi$w1_general_health)
```

Lastly, we check teenagers with a BMI over 30. This is considered a very high score for teenagers, and still most of them classify their own health as good. Therefore, we need to be careful in the results of this variable as explaining BMI in wave 5.

## Breakfast

We start by investigating the count of people who have each type of breakfast.

```{r}
df <- data %>% 
  select(
    w1_usual_breakfast_milk
    , w1_usual_breakfast_cereal
    , w1_usual_breakfast_eggs
    , w1_usual_breakfast_fruit
    , w1_usual_breakfast_meat
    , w1_usual_breakfast_snack
    , w1_usual_breakfast_bread
  )

# Count the 'Yes' values for each column
yes_counts <- df %>% 
  summarise(across(everything(), ~ sum(. == 'Yes'))) %>% 
  pivot_longer(cols = everything(), names_to = 'breakfast_item', values_to = 'count_yes')

# Create the bar plot
ggplot(yes_counts, aes(x = breakfast_item, y = count_yes)) +
  geom_bar(stat = 'identity', fill = 'skyblue', color='black') +
  theme_minimal() +
  labs(title = 'Count of Yes per Breakfast Item',
       x = 'Breakfast Item',
       y = 'Count of Yes') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

We see that it is likely that cereal and milk have a high correlation score. Other than this, the distribution is according to our expectations.

## Education

Finally we look into the proportion of children who were exposed to the relevant topics in school.

```{r}
df <- data %>% 
  select(
    w1_learned_diet
    , w1_learned_problems_obesity
    , w1_learned_importance_exercise
  )

# Count the 'Yes' values for each column
yes_counts <- df %>% 
  summarise(across(everything(), ~ sum(. == 'Yes'))) %>% 
  pivot_longer(cols = everything(), names_to = 'learning_topic', values_to = 'count_yes')

# Create the bar plot
ggplot(yes_counts, aes(x = learning_topic, y = count_yes)) +
  geom_bar(stat = 'identity', fill = 'skyblue', color='black') +
  theme_minimal() +
  labs(title = 'Count of Yes per learning Topic',
       x = 'Learning Topic',
       y = 'Count of Yes') +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

We see that in that year, topics around dieting and the importance of exercise were already present in schools.

# Regression

We start understanding the relationship between our variables. We split the independent variables in four groups:

1.  Wave 1 background
2.  Wave 1 baseline health indicators
3.  Wave 1 dieting educational factors
4.  Wave 5 habits

We start with a simple regression on the selected variables

```{r}
ols1 = lm(w5_bmi ~  
                  # Wave 1 background
                  + w1_income_1994_log_win
                  + w1_ethnicity
                  + w1_urbanity
                  + BIO_SEX
                  # Wave 1 baseline health indicators
                  + w1_bmi
                  + w1_general_health_int
                  # Dieting educational factors
                  + w1_learned_diet
                  + w1_dinner_with_parents
                  + w1_learned_problems_obesity
                  + w1_learned_importance_exercise
                  + w1_usual_breakfast_cereal
                  + w1_usual_breakfast_fruit
                  + w1_usual_breakfast_eggs
                  + w1_usual_breakfast_meat
                  + w1_usual_breakfast_snack
                  + w1_usual_breakfast_bread
                  # Wave 5 habits
                  + w5_exercise
         , data=data)

stargazer(ols1,
          type="text",
          single.row = TRUE,
          header = FALSE,
          title = "Simple regression - No changes")
```

We observe that the BMI level in wave 1 is still the second most relevant factor in explaining the BMI in wave 5. Therefore, we try a second approach: Paneling the data for children that were not overweight and became overweight. We define this transition as children who had a BMI of less than 25 in wave 1 and in wave 5 were over 30.

```{r}
data$w5_become_overweight <- ifelse(data$w1_bmi < 25 & data$w5_bmi > 30, 1, 0)

# Check the distribution again
ggplot(data, aes(x = w5_become_overweight)) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Distribution of Urban (Cleaned)", x = "Become overweight", y = "Count") +
  theme_minimal()
```

## Panel 1: Children who were not overweight and became overweight

The first panel is the same simple regression from before applied only to the children that transitioned from not overweight to overweight in wave 5

```{r}
# Get only children that transitioned from not overweight to overweight
data_panel_1 <- data[(data$w1_bmi < 25) & (data$w5_bmi > 30),]

ols2 = lm(w5_bmi ~  
                  # Wave 5 habits
                  + w5_exercise
                  # Wave 1 background
                  + BIO_SEX
                  + w1_ethnicity
                  + w1_urbanity
                  + w1_income_1994_log_win
                  # Wave 1 baseline health indicators
                  + w1_bmi
                  + w1_general_health_int
                  # Dieting educational factors
                  + w1_learned_diet
                  + w1_dinner_with_parents
                  + w1_learned_problems_obesity
                  + w1_learned_importance_exercise
                  + w1_usual_breakfast_cereal
                  + w1_usual_breakfast_fruit
                  + w1_usual_breakfast_eggs
                  + w1_usual_breakfast_meat
                  + w1_usual_breakfast_snack
                  + w1_usual_breakfast_bread
         , data=data_panel_1)

stargazer(ols2,
          type="text",
          single.row = TRUE,
          header = FALSE,
          title = "Panel 1: Children who were not overweight and became overweight")
```

```{r}
# Check the distribution again
ggplot(data_panel_1 %>% na.omit(), aes(x = BIO_SEX)) +
  geom_bar(fill = "skyblue", color = "black") +
  labs(title = "Panel 2 distribution", x = "Become overweight", y = "Count") +
  theme_minimal()
```

## Panel 2: Children who did not transition

```{r}
# Get only children that did not transition from not overweight to overweight
data_panel_2 <- data[!((data$w1_bmi < 25) & (data$w5_bmi > 30)),]

ols3 = lm(w5_bmi ~  
                  # Wave 5 habits
                  + w5_exercise
                  # Wave 1 background
                  + BIO_SEX
                  + w1_ethnicity
                  + w1_urbanity
                  + w1_income_1994_log_win
                  # Wave 1 baseline health indicators
                  + w1_bmi
                  + w1_general_health_int
                  # Dieting educational factors
                  + w1_learned_diet
                  + w1_dinner_with_parents
                  + w1_learned_problems_obesity
                  + w1_learned_importance_exercise
                  + w1_usual_breakfast_cereal
                  + w1_usual_breakfast_fruit
                  + w1_usual_breakfast_eggs
                  + w1_usual_breakfast_meat
                  + w1_usual_breakfast_snack
                  + w1_usual_breakfast_bread
         , data=data_panel_2)

stargazer(ols3,
          type="text",
          single.row = TRUE,
          header = FALSE,
          title = "Panel 2: Children who did not transition")
```

## Logit model: Baseline

Next, we set to investigate the transition from not overweight to overweight as a binary variable. Therefore, we fit a logit regression to use as a baseline without the education variables

```{r}
logit = glm(w5_become_overweight ~  
                  # Wave 1 background
                  + BIO_SEX
                  + w1_ethnicity
                  + w1_income_1994_log_win
                  # Wave 1 baseline health indicators
                  + w1_general_health_int
                  # Dieting educational factors
                  + w1_bmi
            , family = 'binomial'
         , data=data)

stargazer(logit,
          type="text",
          single.row = TRUE,
          header = FALSE,
          title = "Logit regression - Become overweight")
```

## Logit model: Explaining the transition

Finally, we build on the baseline to add the education variables.

```{r}
logit = glm(w5_become_overweight ~  
                  # Wave 1 background
                  + BIO_SEX
                  + w1_ethnicity
                  + w1_urbanity
                  + w1_income_1994_log_win
                  # Wave 1 baseline health indicators
                  + w1_general_health_int
                  # Dieting educational factors
                  + w1_learned_diet
                  + w1_learned_importance_exercise
                  + w1_learned_problems_obesity
                  + w1_dinner_with_parents
                  + w1_usual_breakfast_cereal
                  + w1_usual_breakfast_fruit
                  + w1_usual_breakfast_eggs
                  + w1_usual_breakfast_meat
                  + w1_usual_breakfast_snack
                  + w1_usual_breakfast_bread
            , family = 'binomial'
         , data=data)

stargazer(logit,
          type="text",
          single.row = TRUE,
          header = FALSE,
          title = "Logit regression - Become overweight")
```
